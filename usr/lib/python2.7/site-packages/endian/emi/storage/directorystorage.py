#!/usr/bin/env python
# encoding: utf-8
#
# +--------------------------------------------------------------------------+
# | Endian Firewall                                                          |
# +--------------------------------------------------------------------------+
# | Copyright (c) 2005-2011 Endian                                           |
# |         Endian GmbH/Srl                                                  |
# |         Bergweg 41 Via Monte                                             |
# |         39057 Eppan/Appiano                                              |
# |         ITALIEN/ITALIA                                                   |
# |         info@endian.com                                                  |
# |                                                                          |
# | emi is free software: you can redistribute it and/or modify it under     |
# | the terms of GNU General Public License (GPL) version 2.0                |
# | when released with the Community edition                                 |
# | or the GNU Lesser General Public License (LGPL) version 2.1              |
# | when released with the Enterprise edition.                               |
# |                                                                          |
# | emi is distributed in the hope that it will be useful,                   |
# | but WITHOUT ANY WARRANTY; without even the implied warranty of           |
# | MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the             |
# | GNU General Public License for more details or the                       |
# | GNU Lesser General Public License for more details.                      |
# |                                                                          |
# | You should have received a copy of the license along with emi.           |
# | If not, see <http://www.gnu.org/licenses/>.                              |
# +--------------------------------------------------------------------------+
#

import os
import glob
import gzip
import datetime
from endian.emi.storage.cachedstorage import CachedStorage, CacheEntry
from endian.core import logger

__all__ = [
    'DirectoryStorage'
]

class DirectoryCacheEntry(CacheEntry):
    """
        scan the directory for files
    """

    file_modification_time = {}
    file_filter = "*"

    def _store_to_file_cache(self, cache_data={}):
        cache_data["file_modification_time"] = self.file_modification_time
        super(DirectoryCacheEntry, self)._store_to_file_cache(cache_data=cache_data)

    def _restore_from_file_cache(self):
        cache_data = super(DirectoryCacheEntry, self)._restore_from_file_cache()
        self.file_modification_time = cache_data.get("file_modification_time", {})
        return cache_data

    def get_value(self, id):
        info = super(DirectoryCacheEntry, self).get_value(id)
        if info is None:
            return None
        # get not cached info of the file
        try:
            return self.parse_file(info)
        except Exception, ex:
            logger.error("Directory storage '%s' could not parse file '%s' (parse_file): %s" % (self.namespace, info['name'], str(ex)), exc_info=True)
        return None

    def get_values(self):
        values = {}
        try:
            # update directory modification time before reading the list
            # to be sure it did not change during reading
            self._update_modification_time()
            filelist = glob.glob(os.path.join(self.path, self.file_filter))
            total = len(filelist)
            count = 0
            for filepath in filelist:
                count += 1
                # update file modification time before parsing it
                # to be sure it did not change during reading
                filename = os.path.basename(filepath)
                changed, modification_time = self._update_file_modification_time(filepath)
                if not changed and self.values.has_key(filename):
                    info = self.values[filename]
                else:
                    logger.debug("Directory storage '%s' file '%s' expired (%d/%d)" % (self.namespace, filename, count, total))
                    info = {}
                    info['ID'] = filename
                    info['path'] = filepath
                    info['lastmodified'] = datetime.datetime.fromtimestamp(modification_time).strftime('%Y-%m-%d %H:%M:%S')
                    info['name'] = filename
                    info['size'] = float(os.path.getsize(filepath))

                    try:
                        self.parse_file_for_cache(info)
                    except Exception, ex:
                        logger.error("Directory storage '%s' could not parse file '%s' (parse_file_for_cache): %s" % (self.namespace, filename, str(ex)), exc_info=True)
                try:
                    info = self.parse_file_always(info)
                except Exception, ex:
                    logger.error("Directory storage '%s' could not parse file '%s' (parse_file_always): %s" % (self.namespace, filename, str(ex)), exc_info=True)
                values[filename] = info
            logger.debug("Directory storage '%s' loaded (%d items)", self.namespace, len(values))
            self._clean_file_modification_time(values.keys())
        except Exception, ex:
            logger.error("Directory storage '%s' could not read directory '%s': %s" % (self.namespace, self.path, str(ex)), exc_info=True)
            values = {}
        return values

    def read_binary_file(self, path):
        """
            read out the file content for parsing.
            overwrite this method if you have diffrent file types
        """
        if path.endswith(".gz"):
            f = gzip.open(path, "rb")
        else:
            f = open(path, "rb")
        content = f.read()
        f.close()
        return content

    def read_file(self, path):
        """
            read out the file content for parsing.
            overwrite this method if you have diffrent file types
        """
        if path.endswith(".gz"):
            f = gzip.open(path, "r")
        else:
            f = open(path, "r")
        content = f.read()
        f.close()
        return content

    def parse_file_for_cache(self, info):
        """
            Put your code to parse the content of a file here
            info returned by this function will be cached
            Needs to return the info dict
        """
        raise NotImplementedError

    def parse_file_always(self, info):
        """
            Put your code to parse the content of a file here
            info returned by this function will be read always
            it gets the info from parse_file_for_cache
            Needs to return the info dict
        """
        return info

    def parse_file(self, info):
        """
            Put your code to parse the content of a file here
            info returned by this function will not be cached
            it gets the info from parse_file_for_cache and parse_file_always
            Needs to return the info dict
        """
        raise NotImplementedError

    def _delete(self, id):
        """
            Delete the file from the directory
        """
        try:
            os.unlink(os.path.join(self.path, id))
            # delete entry from file_modification_time, otherwhise the cache would be invalidated
            if self.file_modification_time.has_key(id):
                del self.file_modification_time[id]
            return True
        except Exception, ex:
            logger.error("Error deleting file  '%s': %s" % (self.path, str(ex)), exc_info=True)
            raise Exception("Error deleting file '%s': %s" % (self.path, str(ex)))
        return False

    def _save(self):
        """
            The directory storage does not support saving
        """
        # saving a directory is currently not supported
        # not sure if it should be supported
        # so this storage is a readonly storage
        logger.warn("Directory storage does not support save")
        return False

    def _update_file_modification_time(self, filepath):
        key = os.path.basename(filepath)
        modification_time = self._get_modification_time(path=filepath)
        if self.file_modification_time.get(key, 0) >= modification_time:
            return False, modification_time
        self.file_modification_time[key] = modification_time
        return True, modification_time

    def _clean_file_modification_time(self, filenames):
        """
            Make sure entries of files which do not exist anymore are deleted
        """
        for filename in self.file_modification_time.keys():
            if filename not in filenames:
                del self.file_modification_time[filename]

    def is_valid(self):
        valid = super(DirectoryCacheEntry, self).is_valid()
        if not valid:
            return False
        current_modification_time = self._get_file_modification_time()
        if len(current_modification_time.keys()) != len(self.file_modification_time.keys()):
            return False
        for key, value in current_modification_time.iteritems():
            if self.file_modification_time.get(key, 0) < value:
                return False
        return True

    def _get_file_modification_time(self):
        """
            Retrun the file modification time
        """
        file_modification_time = {}
        for filename in os.listdir(self.path):
            filepath = os.path.join(self.path, filename)
            file_modification_time[os.path.basename(filepath)] = self._get_modification_time(path=filepath)
        return file_modification_time

class DirectoryStorage(CachedStorage):
    """
    Load/store files from/to directory.

    Each dictionary needs to have an ID key, that is used for its identification.
    """
    cache_entry_class = DirectoryCacheEntry

    def _get_path(self, namespace):
        return '/%s' % namespace.replace('.','/')
